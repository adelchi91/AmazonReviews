{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "655a4097-c9b8-4383-b64d-5213b856db84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adelchiasta/venv/venv_abwab/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from datetime import datetime\n",
    "# import multiprocessing as mp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11d160-f0b8-4bfe-8fd5-9988379c4480",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c4ec6f-74ff-4060-8230-0f68159ec2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file amazon_reviews_beauty.joblib exists in the folder.\n"
     ]
    }
   ],
   "source": [
    "full_path = \"../data/amazon_reviews_beauty.joblib\"\n",
    "file_name = \"amazon_reviews_beauty.joblib\"\n",
    "if os.path.exists(full_path):\n",
    "    print(f\"The file {file_name} exists in the folder.\")\n",
    "    # Load the joblib file\n",
    "    df = joblib.load('../data/amazon_reviews_beauty.joblib')\n",
    "else:\n",
    "    print(f\"The file {file_name} does not exists in the folder. Importing...\")\n",
    "    # Load the review dataset\n",
    "    review_dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_review_All_Beauty\", split=\"full\", trust_remote_code=True)\n",
    "    # Load the metadata dataset\n",
    "    meta_dataset = load_dataset(\"McAuley-Lab/Amazon-Reviews-2023\", \"raw_meta_All_Beauty\", split=\"full\", trust_remote_code=True)\n",
    "    # Convert datasets to pandas DataFrames\n",
    "    df_reviews = pd.DataFrame(review_dataset).sample(n=10000, random_state=2024)\n",
    "    df_meta = pd.DataFrame(meta_dataset)\n",
    "    # Merge the datasets on parent_asin\n",
    "    df = pd.merge(df_reviews, df_meta, on='parent_asin', how='left', suffixes=('_review', '_meta'))\n",
    "    # Save the DataFrame as a joblib file\n",
    "    joblib.dump(df, '../data/amazon_reviews_beauty.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb0323a2-2bf8-49c5-a77a-a9ce4eb2828f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rating', 'title_review', 'text', 'images_review', 'asin',\n",
       "       'parent_asin', 'user_id', 'timestamp', 'helpful_vote',\n",
       "       'verified_purchase', 'main_category', 'title_meta', 'average_rating',\n",
       "       'rating_number', 'features', 'description', 'price', 'images_meta',\n",
       "       'videos', 'store', 'categories', 'details', 'bought_together',\n",
       "       'subtitle', 'author'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8c2618d-ef57-4815-b593-817ca4743b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb58b048-3a1a-46dc-9a80-a272fad72ff4",
   "metadata": {},
   "source": [
    "# 2. Outliers scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b324135-f73f-4af4-bb75-3c26de6b66cf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.1 Firt version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32df5feb-b916-46a0-9c82-05aca947a1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data preparation complete.\n",
      "Running outlier detection pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:  20%|█████████████████▌                                                                      | 1/5 [00:02<00:10,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average similarity (first 10): [[0.03610338]\n",
      " [0.02530873]\n",
      " [0.04091656]\n",
      " [0.05355231]\n",
      " [0.02495647]\n",
      " [0.02806567]\n",
      " [0.0405637 ]\n",
      " [0.03375799]\n",
      " [0.04532672]\n",
      " [0.02853394]]\n",
      "Mean similarity: 0.035800519662544855\n",
      "Standard deviation of similarity: 0.011623486776102018\n",
      "Z-scores (first 10): [[ 0.0260563 ]\n",
      " [-0.90263711]\n",
      " [ 0.44014649]\n",
      " [ 1.52723454]\n",
      " [-0.93294272]\n",
      " [-0.66544998]\n",
      " [ 0.40978894]\n",
      " [-0.17572411]\n",
      " [ 0.81956509]\n",
      " [-0.62516367]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier detection complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class TemporalOutlierDetector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Detect temporal outliers based on review counts within specified time windows.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    time_column : str, default='timestamp'\n",
    "        Name of the column containing timestamp information.\n",
    "    window_size : str, default='D'\n",
    "        Size of the time window for grouping reviews (e.g., 'D' for daily).\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    fit(X, y=None)\n",
    "        Fit method required by scikit-learn's BaseEstimator. Returns self.\n",
    "    transform(X)\n",
    "        Transform method to calculate temporal outlier flags based on review counts.\n",
    "        Returns a numpy array of temporal outlier flags.\n",
    "\n",
    "    Explanation:\n",
    "    ------------\n",
    "    This class groups the data by time periods defined by `window_size`, counts reviews within each period,\n",
    "    and identifies temporal outliers based on a threshold of review counts.\n",
    "    \"\"\"\n",
    "    def __init__(self, time_column='timestamp', window_size='D'):\n",
    "        self.time_column = time_column\n",
    "        self.window_size = window_size\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform method to calculate temporal outlier flags based on review counts.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas DataFrame\n",
    "            Input data with timestamp information.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Numpy array containing temporal outlier flags (1 for outlier, 0 otherwise).\n",
    "        \"\"\"\n",
    "        X = X.copy()\n",
    "        X['datetime'] = pd.to_datetime(X[self.time_column], unit='s', errors='coerce')\n",
    "        X['review_count'] = X.groupby(X['datetime'].dt.to_period(self.window_size))['datetime'].transform('count')\n",
    "        X['temporal_outlier'] = (X['review_count'] > X['review_count'].quantile(0.95)).astype(int)\n",
    "        return X[['temporal_outlier']].values  # Return numpy array\n",
    "\n",
    "class BehavioralOutlierDetector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Detect behavioral outliers based on user review patterns and rating deviations.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    user_column : str, default='user_id'\n",
    "        Name of the column containing user identifiers.\n",
    "    time_column : str, default='timestamp'\n",
    "        Name of the column containing timestamp information.\n",
    "    rating_column : str, default='rating'\n",
    "        Name of the column containing rating information.\n",
    "    window_size : str, default='D'\n",
    "        Size of the time window for grouping reviews (e.g., 'D' for daily).\n",
    "    review_threshold : int, default=3\n",
    "        Threshold for identifying high-frequency users based on review counts.\n",
    "    rating_deviation_threshold : float, default=1.5\n",
    "        Threshold for identifying users with rating deviations from overall averages.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    fit(X, y=None)\n",
    "        Fit method required by scikit-learn's BaseEstimator. Returns self.\n",
    "    transform(X)\n",
    "        Transform method to calculate behavioral outlier flags based on user behavior.\n",
    "        Returns a numpy array of behavioral outlier flags.\n",
    "\n",
    "    Explanation:\n",
    "    ------------\n",
    "    This class identifies behavioral outliers among users based on two criteria: high-frequency reviewing\n",
    "    and rating deviations. It computes user review counts and average ratings, identifies high-frequency\n",
    "    users and users with rating deviations, and flags outliers accordingly.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, user_column='user_id', time_column='timestamp', rating_column='rating', window_size='D', review_threshold=3, rating_deviation_threshold=1.5):\n",
    "        self.user_column = user_column\n",
    "        self.time_column = time_column\n",
    "        self.rating_column = rating_column\n",
    "        self.window_size = window_size\n",
    "        self.review_threshold = review_threshold\n",
    "        self.rating_deviation_threshold = rating_deviation_threshold\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transform method to calculate behavioral outlier flags based on user behavior.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : pandas DataFrame\n",
    "            Input data with user, timestamp, and rating information.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        numpy.ndarray\n",
    "            Numpy array containing behavioral outlier flags (1 for outlier, 0 otherwise).\n",
    "        \"\"\"\n",
    "        X = X.copy()\n",
    "        X['datetime'] = pd.to_datetime(X[self.time_column], unit='s', errors='coerce')\n",
    "        \n",
    "        user_review_counts = X.groupby([self.user_column, X['datetime'].dt.to_period(self.window_size)]).size().reset_index(name='review_count')\n",
    "        high_frequency_users = user_review_counts[user_review_counts['review_count'] > self.review_threshold][self.user_column].unique()\n",
    "        \n",
    "        user_avg_ratings = X.groupby(self.user_column)[self.rating_column].mean()\n",
    "        overall_avg_rating = X[self.rating_column].mean()\n",
    "        deviating_users = user_avg_ratings[abs(user_avg_ratings - overall_avg_rating) > self.rating_deviation_threshold].index\n",
    "        \n",
    "        X['high_frequency_outlier'] = X[self.user_column].isin(high_frequency_users).astype(int)\n",
    "        X['rating_deviation_outlier'] = X[self.user_column].isin(deviating_users).astype(int)\n",
    "        \n",
    "        return X[['high_frequency_outlier', 'rating_deviation_outlier']].values  # Return numpy array\n",
    "\n",
    "# def text_outliers(text_data, threshold=0.1):\n",
    "#     vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "#     tfidf_matrix = vectorizer.fit_transform(text_data)\n",
    "#     cosine_sim = cosine_similarity(tfidf_matrix, dense_output=False)\n",
    "#     avg_similarity = np.mean(cosine_sim, axis=1)\n",
    "#     return (avg_similarity < threshold).astype(int).reshape(-1, 1)  # Return 2D numpy array\n",
    "\n",
    "def text_outliers(text_data, z_score_threshold):\n",
    "    \"\"\"\n",
    "    Identify text outliers based on cosine similarity scores.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text_data : list or array-like\n",
    "        List of text documents to analyze.\n",
    "    z_score_threshold : float\n",
    "        Threshold value for identifying outliers based on z-scores of cosine similarities.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Numpy array containing text outlier flags (1 for outlier, 0 otherwise).\n",
    "\n",
    "    Explanation:\n",
    "    ------------\n",
    "    This function calculates cosine similarity scores for text documents represented as TF-IDF vectors,\n",
    "    computes z-scores based on the distribution of these scores, and identifies outliers based on a\n",
    "    dynamically determined threshold (`z_score_threshold`).\n",
    "    \"\"\"\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(text_data)\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, dense_output=False)\n",
    "    avg_similarity = np.mean(cosine_sim, axis=1)\n",
    "    \n",
    "    # Print debug information\n",
    "    print(\"Average similarity (first 10):\", avg_similarity[:10])\n",
    "    \n",
    "    mean_sim = np.mean(avg_similarity)\n",
    "    std_sim = np.std(avg_similarity)\n",
    "    z_scores = (avg_similarity - mean_sim) / std_sim\n",
    "    \n",
    "    # Print more debug information\n",
    "    print(\"Mean similarity:\", mean_sim)\n",
    "    print(\"Standard deviation of similarity:\", std_sim)\n",
    "    print(\"Z-scores (first 10):\", z_scores[:10])\n",
    "    \n",
    "    return (z_scores < -z_score_threshold).astype(int).reshape(-1, 1)\n",
    "\n",
    "# def main_code(df):\n",
    "# Prepare the data\n",
    "print(\"Preparing data...\")\n",
    "df['helpful_vote'] = pd.to_numeric(df['helpful_vote'], errors='coerce')\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "df['verified_purchase'] = df['verified_purchase'].astype(int)\n",
    "# Ensure text columns are converted to strings\n",
    "text_columns = ['title_review', 'text', 'main_category', 'title_meta', 'description']\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "df['combined_text'] = df['title_review'] + ' ' + df['text'] + ' ' + df['main_category'] + ' ' + df['title_meta'] + ' ' + df['description']\n",
    "\n",
    "# Handle missing values\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "# For non-numeric columns, fill with a placeholder\n",
    "non_numeric_columns = df.select_dtypes(exclude=[np.number]).columns\n",
    "for col in non_numeric_columns:\n",
    "    df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "# Convert timestamp to datetime and handle invalid values\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', errors='coerce')\n",
    "\n",
    "print(\"Data preparation complete.\")\n",
    "\n",
    "# Define the feature pipeline\n",
    "feature_pipeline = ColumnTransformer([\n",
    "    ('num', StandardScaler(), ['rating', 'helpful_vote', 'verified_purchase', 'price', 'average_rating', 'rating_number']),\n",
    "    ('text', FunctionTransformer(text_outliers, kw_args={'z_score_threshold': 35}), 'combined_text'),\n",
    "    ('temporal', TemporalOutlierDetector(), ['timestamp']),\n",
    "    ('behavioral', BehavioralOutlierDetector(), ['user_id', 'timestamp', 'rating'])\n",
    "])\n",
    "\n",
    "# Fit and transform the data using the pipeline\n",
    "print(\"Running outlier detection pipeline...\")\n",
    "with tqdm(total=5, desc=\"Processing\") as pbar:\n",
    "    # Transform features\n",
    "    X_transformed = feature_pipeline.fit_transform(df)\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Ensure X_transformed is a 2D numpy array\n",
    "    X_transformed = np.asarray(X_transformed)\n",
    "    if X_transformed.ndim == 1:\n",
    "        X_transformed = X_transformed.reshape(-1, 1)\n",
    "\n",
    "    # Isolation Forest\n",
    "    iso_forest = IsolationForest(contamination=0.1, random_state=42, n_jobs=-1)\n",
    "    iso_forest_outliers = iso_forest.fit_predict(X_transformed)\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Local Outlier Factor\n",
    "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1, n_jobs=-1)\n",
    "    lof_outliers = lof.fit_predict(X_transformed)\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Add outlier results to the dataframe\n",
    "    df['isolation_forest_outlier'] = (iso_forest_outliers == -1).astype(int)\n",
    "    df['lof_outlier'] = (lof_outliers == -1).astype(int)\n",
    "    # Convert small float values to 0 or 1\n",
    "    df['text_outlier'] = (X_transformed[:, 0] > 0.5).astype(int)\n",
    "    df['temporal_outlier'] = (X_transformed[:, 1] > 0.5).astype(int)\n",
    "    df['high_frequency_outlier'] = (X_transformed[:, 2] > 0.5).astype(int)\n",
    "    df['rating_deviation_outlier'] = (X_transformed[:, 3] > 0.5).astype(int)\n",
    "    pbar.update(1)\n",
    "\n",
    "    # Calculate overall outlier score\n",
    "    df['outlier_score'] = (df['isolation_forest_outlier'] + \n",
    "                           df['lof_outlier'] + \n",
    "                           df['text_outlier'] + \n",
    "                           df['temporal_outlier'] + \n",
    "                           df['high_frequency_outlier'] + \n",
    "                           df['rating_deviation_outlier'])\n",
    "    # Mark as outlier if at least two methods flagged it as an outlier\n",
    "    df['is_outlier'] = (df['outlier_score'] >= 2).astype(int)\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"Outlier detection complete.\")\n",
    "\n",
    "# # Identify samples most likely to be outliers\n",
    "# top_outliers = df.nlargest(10, 'outlier_score')\n",
    "# print(\"\\nTop 10 potential outliers:\")\n",
    "# print(top_outliers[['rating', 'helpful_vote', 'verified_purchase', 'price', 'outlier_score', 'title_review', 'main_category', 'high_frequency_outlier', 'rating_deviation_outlier']])\n",
    "\n",
    "# # Calculate metrics\n",
    "# total_samples = len(df)\n",
    "# print(f\"\\nOutlier Detection Results:\")\n",
    "# for outlier_type in ['isolation_forest_outlier', 'lof_outlier', 'text_outlier', 'temporal_outlier', 'high_frequency_outlier', 'rating_deviation_outlier']:\n",
    "#     count = df[outlier_type].sum()\n",
    "#     print(f\"{outlier_type}: {count} outliers ({count/total_samples:.2%})\")\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# main_code(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0bdb05f1-7207-4695-a897-3a184ad485a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 potential outliers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title_review</th>\n",
       "      <th>text</th>\n",
       "      <th>images_review</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>...</th>\n",
       "      <th>author</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>isolation_forest_outlier</th>\n",
       "      <th>lof_outlier</th>\n",
       "      <th>text_outlier</th>\n",
       "      <th>temporal_outlier</th>\n",
       "      <th>high_frequency_outlier</th>\n",
       "      <th>rating_deviation_outlier</th>\n",
       "      <th>outlier_score</th>\n",
       "      <th>is_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4354</th>\n",
       "      <td>5.0</td>\n",
       "      <td>All the perfect star reviews on here are correct</td>\n",
       "      <td>All the perfect star reviews on here are corre...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B01D2IXB20</td>\n",
       "      <td>B01D2IXB20</td>\n",
       "      <td>AED24UIY2S3ACO4U5XAHOVF4HU6Q</td>\n",
       "      <td>NaT</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>All the perfect star reviews on here are corre...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I pray this sproduct NEVER gets discontinued !</td>\n",
       "      <td>I have usded this product around my eyes for o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B01IA95GV0</td>\n",
       "      <td>B01IA95GV0</td>\n",
       "      <td>AFA3ROXMMCIMZVLXNGYA2ZXZDNTQ</td>\n",
       "      <td>NaT</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>I pray this sproduct NEVER gets discontinued !...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Looks beautiful</td>\n",
       "      <td>Works perfectly in the salon for color process...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B005EUEK4S</td>\n",
       "      <td>B005EUEK4S</td>\n",
       "      <td>AFOMGW34K26S4NHKWSMYTSBITTQQ</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Looks beautiful Works perfectly in the salon f...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Duradero</td>\n",
       "      <td>Siempre que uso este perfume me alagan y creen...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B08739QVNW</td>\n",
       "      <td>B0BTJ6SYKB</td>\n",
       "      <td>AE7UXIOTHPPS54LJV2G6EHMTCBFQ</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Duradero Siempre que uso este perfume me alaga...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Perfect 😍</td>\n",
       "      <td>I lovvvvveeeeee it!!!! You can't go wrong with...</td>\n",
       "      <td>[{'attachment_type': 'IMAGE', 'large_image_url...</td>\n",
       "      <td>B06Y22GS6X</td>\n",
       "      <td>B06Y22GS6X</td>\n",
       "      <td>AEBPCYFU5LWAYDN35KZEBND77SCQ</td>\n",
       "      <td>NaT</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Perfect 😍 I lovvvvveeeeee it!!!! You can't go ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>5.0</td>\n",
       "      <td>If you have smelly pits you need this!!!</td>\n",
       "      <td>Before anything you won’t receive expired deod...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B072Y3CGRX</td>\n",
       "      <td>B072Y3CGRX</td>\n",
       "      <td>AHPICTZYV5JFT55CXJ2EOAERLYJQ</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>If you have smelly pits you need this!!! Befor...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>5.0</td>\n",
       "      <td>So Cute!</td>\n",
       "      <td>The headbands are so cute!  I love the colors ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B072K1ZW8L</td>\n",
       "      <td>B09FP8PP2K</td>\n",
       "      <td>AFLR6AKBXXIYLBTERI5KAG3I7TTA</td>\n",
       "      <td>NaT</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>So Cute! The headbands are so cute!  I love th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The hint you’ve all been waiting for..</td>\n",
       "      <td>Listen up ya’ll - so many people (me included)...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07V6RQGRR</td>\n",
       "      <td>B07V6RQGRR</td>\n",
       "      <td>AFDRB6KJKCI67P3LTWAIULAZGOJA</td>\n",
       "      <td>NaT</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The hint you’ve all been waiting for.. Listen ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Fantastic!</td>\n",
       "      <td>I really like this product. There is a learnin...</td>\n",
       "      <td>[{'attachment_type': 'IMAGE', 'large_image_url...</td>\n",
       "      <td>B07ZJKVVLW</td>\n",
       "      <td>B07ZJKVVLW</td>\n",
       "      <td>AFD6UD3I66OFS3ZNXACZKTSZPYVQ</td>\n",
       "      <td>NaT</td>\n",
       "      <td>389</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Fantastic! I really like this product. There i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3297</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Amazing Deal</td>\n",
       "      <td>Amazing wig!  I can't believe how nice this is...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B00ITMWBFI</td>\n",
       "      <td>B00ITMWBFI</td>\n",
       "      <td>AFVWTIFV725AOUFM32QM74EPQIJA</td>\n",
       "      <td>NaT</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Amazing Deal Amazing wig!  I can't believe how...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      rating                                      title_review  \\\n",
       "4354     5.0  All the perfect star reviews on here are correct   \n",
       "77       5.0    I pray this sproduct NEVER gets discontinued !   \n",
       "312      5.0                                   Looks beautiful   \n",
       "508      5.0                                          Duradero   \n",
       "1049     5.0                                         Perfect 😍   \n",
       "1481     5.0          If you have smelly pits you need this!!!   \n",
       "1728     5.0                                          So Cute!   \n",
       "3174     5.0            The hint you’ve all been waiting for..   \n",
       "3243     5.0                                        Fantastic!   \n",
       "3297     5.0                                      Amazing Deal   \n",
       "\n",
       "                                                   text  \\\n",
       "4354  All the perfect star reviews on here are corre...   \n",
       "77    I have usded this product around my eyes for o...   \n",
       "312   Works perfectly in the salon for color process...   \n",
       "508   Siempre que uso este perfume me alagan y creen...   \n",
       "1049  I lovvvvveeeeee it!!!! You can't go wrong with...   \n",
       "1481  Before anything you won’t receive expired deod...   \n",
       "1728  The headbands are so cute!  I love the colors ...   \n",
       "3174  Listen up ya’ll - so many people (me included)...   \n",
       "3243  I really like this product. There is a learnin...   \n",
       "3297  Amazing wig!  I can't believe how nice this is...   \n",
       "\n",
       "                                          images_review        asin  \\\n",
       "4354                                                 []  B01D2IXB20   \n",
       "77                                                   []  B01IA95GV0   \n",
       "312                                                  []  B005EUEK4S   \n",
       "508                                                  []  B08739QVNW   \n",
       "1049  [{'attachment_type': 'IMAGE', 'large_image_url...  B06Y22GS6X   \n",
       "1481                                                 []  B072Y3CGRX   \n",
       "1728                                                 []  B072K1ZW8L   \n",
       "3174                                                 []  B07V6RQGRR   \n",
       "3243  [{'attachment_type': 'IMAGE', 'large_image_url...  B07ZJKVVLW   \n",
       "3297                                                 []  B00ITMWBFI   \n",
       "\n",
       "     parent_asin                       user_id timestamp  helpful_vote  \\\n",
       "4354  B01D2IXB20  AED24UIY2S3ACO4U5XAHOVF4HU6Q       NaT            15   \n",
       "77    B01IA95GV0  AFA3ROXMMCIMZVLXNGYA2ZXZDNTQ       NaT             5   \n",
       "312   B005EUEK4S  AFOMGW34K26S4NHKWSMYTSBITTQQ       NaT             2   \n",
       "508   B0BTJ6SYKB  AE7UXIOTHPPS54LJV2G6EHMTCBFQ       NaT             4   \n",
       "1049  B06Y22GS6X  AEBPCYFU5LWAYDN35KZEBND77SCQ       NaT             4   \n",
       "1481  B072Y3CGRX  AHPICTZYV5JFT55CXJ2EOAERLYJQ       NaT             0   \n",
       "1728  B09FP8PP2K  AFLR6AKBXXIYLBTERI5KAG3I7TTA       NaT            11   \n",
       "3174  B07V6RQGRR  AFDRB6KJKCI67P3LTWAIULAZGOJA       NaT            21   \n",
       "3243  B07ZJKVVLW  AFD6UD3I66OFS3ZNXACZKTSZPYVQ       NaT           389   \n",
       "3297  B00ITMWBFI  AFVWTIFV725AOUFM32QM74EPQIJA       NaT            10   \n",
       "\n",
       "      verified_purchase  ...   author  \\\n",
       "4354                  1  ...  Unknown   \n",
       "77                    0  ...  Unknown   \n",
       "312                   1  ...  Unknown   \n",
       "508                   1  ...  Unknown   \n",
       "1049                  0  ...  Unknown   \n",
       "1481                  0  ...  Unknown   \n",
       "1728                  1  ...  Unknown   \n",
       "3174                  0  ...  Unknown   \n",
       "3243                  1  ...  Unknown   \n",
       "3297                  0  ...  Unknown   \n",
       "\n",
       "                                          combined_text  \\\n",
       "4354  All the perfect star reviews on here are corre...   \n",
       "77    I pray this sproduct NEVER gets discontinued !...   \n",
       "312   Looks beautiful Works perfectly in the salon f...   \n",
       "508   Duradero Siempre que uso este perfume me alaga...   \n",
       "1049  Perfect 😍 I lovvvvveeeeee it!!!! You can't go ...   \n",
       "1481  If you have smelly pits you need this!!! Befor...   \n",
       "1728  So Cute! The headbands are so cute!  I love th...   \n",
       "3174  The hint you’ve all been waiting for.. Listen ...   \n",
       "3243  Fantastic! I really like this product. There i...   \n",
       "3297  Amazing Deal Amazing wig!  I can't believe how...   \n",
       "\n",
       "      isolation_forest_outlier  lof_outlier text_outlier temporal_outlier  \\\n",
       "4354                         1            1            1                1   \n",
       "77                           1            1            1                1   \n",
       "312                          1            1            1                0   \n",
       "508                          0            1            1                1   \n",
       "1049                         1            1            1                1   \n",
       "1481                         1            1            1                0   \n",
       "1728                         1            1            1                1   \n",
       "3174                         1            1            1                1   \n",
       "3243                         1            1            1                1   \n",
       "3297                         1            1            1                1   \n",
       "\n",
       "      high_frequency_outlier rating_deviation_outlier outlier_score is_outlier  \n",
       "4354                       0                        1             5          1  \n",
       "77                         0                        0             4          1  \n",
       "312                        0                        1             4          1  \n",
       "508                        0                        1             4          1  \n",
       "1049                       0                        0             4          1  \n",
       "1481                       0                        1             4          1  \n",
       "1728                       0                        0             4          1  \n",
       "3174                       0                        0             4          1  \n",
       "3243                       0                        0             4          1  \n",
       "3297                       0                        0             4          1  \n",
       "\n",
       "[10 rows x 34 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify samples most likely to be outliers\n",
    "top_outliers = df.nlargest(10, 'outlier_score')\n",
    "print(\"\\nTop 10 potential outliers:\")\n",
    "top_outliers#[['rating', 'helpful_vote', 'verified_purchase', 'price', 'outlier_score', 'title_review', 'main_category', 'high_frequency_outlier', 'rating_deviation_outlier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5159742-2a03-411e-8a53-933db75261bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outlier Detection Results:\n",
      "isolation_forest_outlier: 1000 outliers (10.00%)\n",
      "lof_outlier: 1000 outliers (10.00%)\n",
      "text_outlier: 6080 outliers (60.80%)\n",
      "temporal_outlier: 550 outliers (5.50%)\n",
      "high_frequency_outlier: 0 outliers (0.00%)\n",
      "rating_deviation_outlier: 540 outliers (5.40%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "total_samples = len(df)\n",
    "print(f\"\\nOutlier Detection Results:\")\n",
    "for outlier_type in ['isolation_forest_outlier', 'lof_outlier', 'text_outlier', 'temporal_outlier', 'high_frequency_outlier', 'rating_deviation_outlier']:\n",
    "    count = df[outlier_type].sum()\n",
    "    print(f\"{outlier_type}: {count} outliers ({count/total_samples:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbd37fb8-6feb-4444-9382-eaf94b3104d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isolation_forest_outlier</th>\n",
       "      <th>lof_outlier</th>\n",
       "      <th>text_outlier</th>\n",
       "      <th>temporal_outlier</th>\n",
       "      <th>high_frequency_outlier</th>\n",
       "      <th>rating_deviation_outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      isolation_forest_outlier  lof_outlier  text_outlier  temporal_outlier  \\\n",
       "0                            0            0             1                 0   \n",
       "1                            0            0             0                 0   \n",
       "2                            0            0             1                 0   \n",
       "3                            0            0             1                 0   \n",
       "4                            0            0             0                 0   \n",
       "...                        ...          ...           ...               ...   \n",
       "9995                         0            1             1                 0   \n",
       "9996                         0            0             0                 0   \n",
       "9997                         0            0             1                 0   \n",
       "9998                         0            1             1                 0   \n",
       "9999                         0            0             0                 0   \n",
       "\n",
       "      high_frequency_outlier  rating_deviation_outlier  \n",
       "0                          0                         0  \n",
       "1                          0                         0  \n",
       "2                          0                         0  \n",
       "3                          0                         0  \n",
       "4                          0                         0  \n",
       "...                      ...                       ...  \n",
       "9995                       0                         0  \n",
       "9996                       0                         0  \n",
       "9997                       0                         0  \n",
       "9998                       0                         0  \n",
       "9999                       0                         0  \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['isolation_forest_outlier', 'lof_outlier', 'text_outlier', 'temporal_outlier', 'high_frequency_outlier', 'rating_deviation_outlier']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3bb7365a-30d3-4463-ad5f-01f22fe02112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.3542795232936078)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df[\"parent_asin\"].value_counts().values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7dcf8243-a331-4862-9015-8d16cb05706b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parent_asin\n",
       "1477044280     1\n",
       "6041134546     1\n",
       "B000050FDE     3\n",
       "B000068PBJ     1\n",
       "B000068PBL     1\n",
       "              ..\n",
       "B0C7WQK2QW     1\n",
       "B0C9CWKY9G    17\n",
       "B0CC929DZZ     1\n",
       "B0CDH5TH82     2\n",
       "B0CDNZ7F2V     4\n",
       "Length: 7384, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('parent_asin').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1e134c-abe2-4ac9-99dc-316f0c2aea42",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.2 Second version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dcb3834-f542-417f-a539-2bc6aab4bc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data preparation complete.\n"
     ]
    }
   ],
   "source": [
    "class TemporalOutlierDetector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, time_column='timestamp', window_size='D', group_column='parent_asin'):\n",
    "        self.time_column = time_column\n",
    "        self.window_size = window_size\n",
    "        self.group_column = group_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['datetime'] = pd.to_datetime(X[self.time_column], unit='s', errors='coerce')\n",
    "        X['review_count'] = X.groupby([self.group_column, X['datetime'].dt.to_period(self.window_size)])['datetime'].transform('count')\n",
    "        X['temporal_outlier'] = (X['review_count'] > X.groupby(self.group_column)['review_count'].transform(lambda x: x.quantile(0.95))).astype(int)\n",
    "        return X[['temporal_outlier']].values\n",
    "\n",
    "\n",
    "class BehavioralOutlierDetector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, user_column='user_id', time_column='timestamp', rating_column='rating', window_size='D', review_threshold=3, rating_deviation_threshold=1.5, group_column='parent_asin'):\n",
    "        self.user_column = user_column\n",
    "        self.time_column = time_column\n",
    "        self.rating_column = rating_column\n",
    "        self.window_size = window_size\n",
    "        self.review_threshold = review_threshold\n",
    "        self.rating_deviation_threshold = rating_deviation_threshold\n",
    "        self.group_column = group_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['datetime'] = pd.to_datetime(X[self.time_column], unit='s', errors='coerce')\n",
    "\n",
    "        # High-frequency user detection\n",
    "        user_review_counts = X.groupby([self.group_column, self.user_column, X['datetime'].dt.to_period(self.window_size)]).size().reset_index(name='review_count')\n",
    "        high_frequency_users = user_review_counts[user_review_counts['review_count'] > self.review_threshold][self.user_column].unique()\n",
    "\n",
    "        # Rating deviation detection\n",
    "        user_avg_ratings = X.groupby([self.group_column, self.user_column])[self.rating_column].mean().reset_index()\n",
    "        overall_avg_ratings = X.groupby(self.group_column)[self.rating_column].mean().reset_index()\n",
    "        deviating_users = user_avg_ratings.merge(overall_avg_ratings, on=self.group_column, suffixes=('_user', '_overall'))\n",
    "        deviating_users['rating_deviation'] = abs(deviating_users[f'{self.rating_column}_user'] - deviating_users[f'{self.rating_column}_overall'])\n",
    "        deviating_users = deviating_users[deviating_users['rating_deviation'] > self.rating_deviation_threshold][self.user_column].unique()\n",
    "\n",
    "        X['high_frequency_outlier'] = X[self.user_column].isin(high_frequency_users).astype(int)\n",
    "        X['rating_deviation_outlier'] = X[self.user_column].isin(deviating_users).astype(int)\n",
    "\n",
    "        return X[['high_frequency_outlier', 'rating_deviation_outlier']].values\n",
    "\n",
    "# def text_outliers(text_data, description_data, group_data, z_score_threshold):\n",
    "#     \"\"\"\n",
    "#     Identify text outliers based on cosine similarity scores with product descriptions.\n",
    "\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     text_data : list or array-like\n",
    "#         List of text documents to analyze (combined text for each review).\n",
    "#     description_data : list or array-like\n",
    "#         List of product descriptions corresponding to each text document.\n",
    "#     group_data : list or array-like\n",
    "#         List of group identifiers (e.g., parent_asin) indicating which product each review belongs to.\n",
    "#     z_score_threshold : float\n",
    "#         Threshold value for identifying outliers based on z-scores of cosine similarities.\n",
    "\n",
    "#     Returns:\n",
    "#     --------\n",
    "#     numpy.ndarray\n",
    "#         Numpy array containing text outlier flags (1 for outlier, 0 otherwise).\n",
    "\n",
    "#     Explanation:\n",
    "#     ------------\n",
    "#     This function calculates cosine similarity scores between each review's combined text and the corresponding\n",
    "#     product description within each product group. It computes z-scores based on the distribution of these scores \n",
    "#     and identifies outliers based on a dynamically determined threshold (`z_score_threshold`).\n",
    "#     \"\"\"\n",
    "#     # Vectorize the text data and description data\n",
    "#     vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "    \n",
    "#     combined_text_tfidf = vectorizer.fit_transform(text_data)\n",
    "#     description_tfidf = vectorizer.transform(description_data)\n",
    "    \n",
    "#     # Initialize array to store outlier flags\n",
    "#     outlier_flags = np.zeros(len(text_data))\n",
    "    \n",
    "#     # Process each group separately\n",
    "#     for group_id in np.unique(group_data):\n",
    "#         # Get indices for the current group\n",
    "#         group_indices = np.where(group_data == group_id)[0]\n",
    "        \n",
    "#         # Extract the text data and description data for the current group\n",
    "#         group_texts = combined_text_tfidf[group_indices]\n",
    "#         group_description = description_tfidf[group_indices[0]]  # Assume description is the same for all in group\n",
    "        \n",
    "#         # Compute cosine similarity between each review's combined text and the group's description\n",
    "#         cosine_sim = np.array([cosine_similarity(group_texts[i], group_description).flatten()[0]\n",
    "#                                for i in range(len(group_texts))])\n",
    "        \n",
    "#         # Calculate z-scores for the cosine similarities\n",
    "#         mean_sim = np.mean(cosine_sim)\n",
    "#         std_sim = np.std(cosine_sim)\n",
    "#         z_scores = (cosine_sim - mean_sim) / std_sim\n",
    "        \n",
    "#         # Identify outliers based on z-scores\n",
    "#         group_outliers = (z_scores < -z_score_threshold).astype(int)\n",
    "        \n",
    "#         # Update the outlier flags for the current group\n",
    "#         outlier_flags[group_indices] = group_outliers\n",
    "    \n",
    "#     return outlier_flags.reshape(-1, 1)\n",
    "\n",
    "def text_outliers(text_data, description_data, group_data, z_score_threshold):\n",
    "    group_texts = text_data\n",
    "    description_tfidf = description_data\n",
    "\n",
    "    group_indices = np.where(group_data == group_data[0])[0]\n",
    "    group_description = description_tfidf[group_indices[0]]  # Assuming description is the same for all in group\n",
    "\n",
    "    # Compute cosine similarity between each review's combined text and the group's description\n",
    "    cosine_sim = np.array([cosine_similarity(group_texts[i], group_description).flatten()[0]\n",
    "                           for i in range(group_texts.shape[0])])\n",
    "\n",
    "    # Calculate z-scores for the cosine similarities\n",
    "    mean_sim = np.mean(cosine_sim)\n",
    "    std_sim = np.std(cosine_sim)\n",
    "    z_scores = (cosine_sim - mean_sim) / std_sim\n",
    "\n",
    "    # Identify outliers based on z-score threshold\n",
    "    outliers = np.where(z_scores > z_score_threshold)[0]\n",
    "\n",
    "    return outliers\n",
    "\n",
    "\n",
    "class TextOutlierTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, z_score_threshold=1.5):\n",
    "        self.z_score_threshold = z_score_threshold\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Assuming X is a DataFrame and the columns are named as expected\n",
    "        combined_text = X['combined_text'].values\n",
    "        description = X['description'].values\n",
    "        parent_asin = X['parent_asin'].values\n",
    "        \n",
    "        return text_outliers(combined_text, description, parent_asin, self.z_score_threshold)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Preparing data...\")\n",
    "df['helpful_vote'] = pd.to_numeric(df['helpful_vote'], errors='coerce')\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "df['verified_purchase'] = df['verified_purchase'].astype(int)\n",
    "# Ensure text columns are converted to strings\n",
    "text_columns = ['title_review', 'text', 'main_category', 'title_meta', 'description']\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "df['combined_text'] = df['title_review'] + ' ' + df['text'] + ' ' + df['main_category'] + ' ' + df['title_meta'] + ' ' + df['description']\n",
    "\n",
    "# Handle missing values\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].fillna(df[col].mean())\n",
    "\n",
    "# For non-numeric columns, fill with a placeholder\n",
    "non_numeric_columns = df.select_dtypes(exclude=[np.number]).columns\n",
    "for col in non_numeric_columns:\n",
    "    df[col] = df[col].fillna(\"Unknown\")\n",
    "\n",
    "# Convert timestamp to datetime and handle invalid values\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', errors='coerce')\n",
    "\n",
    "print(\"Data preparation complete.\")\n",
    "\n",
    "\n",
    "feature_pipeline = ColumnTransformer([\n",
    "    ('num', StandardScaler(), ['rating', 'helpful_vote', 'verified_purchase', 'price', 'average_rating', 'rating_number']),\n",
    "    # ('text', TextOutlierTransformer(z_score_threshold=1.5), ['combined_text', 'description', 'parent_asin']),\n",
    "    ('temporal', TemporalOutlierDetector(group_column='parent_asin'), ['timestamp', 'parent_asin']),\n",
    "    ('behavioral', BehavioralOutlierDetector(group_column='parent_asin'), ['user_id', 'timestamp', 'rating', 'parent_asin'])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76d5732-6df4-4844-84e8-6be01825dec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running outlier detection pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier detection complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Running outlier detection pipeline...\")\n",
    "with tqdm(total=5, desc=\"Processing\") as pbar:\n",
    "    X_transformed = feature_pipeline.fit_transform(df)\n",
    "    pbar.update(1)\n",
    "\n",
    "    X_transformed = np.asarray(X_transformed)\n",
    "    if X_transformed.ndim == 1:\n",
    "        X_transformed = X_transformed.reshape(-1, 1)\n",
    "\n",
    "    iso_forest = IsolationForest(contamination=0.1, random_state=42, n_jobs=-1)\n",
    "    iso_forest_outliers = iso_forest.fit_predict(X_transformed)\n",
    "    pbar.update(1)\n",
    "\n",
    "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1, n_jobs=-1)\n",
    "    lof_outliers = lof.fit_predict(X_transformed)\n",
    "    pbar.update(1)\n",
    "\n",
    "    df['isolation_forest_outlier'] = (iso_forest_outliers == -1).astype(int)\n",
    "    df['lof_outlier'] = (lof_outliers == -1).astype(int)\n",
    "    df['text_outlier'] = (X_transformed[:, 0] > 0.5).astype(int)\n",
    "    df['temporal_outlier'] = (X_transformed[:, 1] > 0.5).astype(int)\n",
    "    df['high_frequency_outlier'] = (X_transformed[:, 2] > 0.5).astype(int)\n",
    "    df['rating_deviation_outlier'] = (X_transformed[:, 3] > 0.5).astype(int)\n",
    "    pbar.update(1)\n",
    "\n",
    "    df['outlier_score'] = (df['isolation_forest_outlier'] + \n",
    "                           df['lof_outlier'] + \n",
    "                           df['text_outlier'] + \n",
    "                           df['temporal_outlier'] + \n",
    "                           df['high_frequency_outlier'] + \n",
    "                           df['rating_deviation_outlier'])\n",
    "    df['is_outlier'] = (df['outlier_score'] >= 2).astype(int)\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"Outlier detection complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d73a5f4-c115-4788-9b94-15f817f1d409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outlier Detection Results:\n",
      "isolation_forest_outlier: 1000 outliers (10.00%)\n",
      "lof_outlier: 1000 outliers (10.00%)\n",
      "text_outlier: 6080 outliers (60.80%)\n",
      "temporal_outlier: 550 outliers (5.50%)\n",
      "high_frequency_outlier: 0 outliers (0.00%)\n",
      "rating_deviation_outlier: 540 outliers (5.40%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "total_samples = len(df)\n",
    "print(f\"\\nOutlier Detection Results:\")\n",
    "for outlier_type in ['isolation_forest_outlier', 'lof_outlier', 'text_outlier', 'temporal_outlier', 'high_frequency_outlier', 'rating_deviation_outlier']:\n",
    "    count = df[outlier_type].sum()\n",
    "    print(f\"{outlier_type}: {count} outliers ({count/total_samples:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd91d4d-ae9c-4856-85a3-4529ad9e7b0a",
   "metadata": {},
   "source": [
    "## 2.3. Third version\n",
    "\n",
    "Dataset characteristics:\n",
    "\n",
    "Amazon reviews typically have multiple reviews per product.\n",
    "However, in your case, you mentioned having a maximum of 20 observations per product and often just 1.\n",
    "This low number of observations per group can indeed cause issues with outlier detection algorithms that rely on local density or isolation concepts.\n",
    "\n",
    "\n",
    "Problems with the current approach:\n",
    "\n",
    "Isolation Forest and LOF work best with larger sample sizes.\n",
    "With only 1-20 observations per group, these methods can't effectively identify outliers within each product group.\n",
    "It may lead to unreliable results or errors, as we've seen.\n",
    "\n",
    "\n",
    "Suggested approach:\n",
    "Instead of grouping by 'parent_asin', it would be more appropriate to apply these methods to the entire dataset. Here's a revised strategy:\n",
    "a. Use global outlier detection:\n",
    "Apply Isolation Forest and LOF to the entire dataset without grouping.\n",
    "b. Retain product-specific features:\n",
    "Include product-specific features (e.g., price, average_rating) in the analysis to capture product-level variations.\n",
    "c. Focus on review-specific features:\n",
    "Emphasize features that are specific to individual reviews (e.g., rating, helpful_vote, verified_purchase).\n",
    "d. Consider temporal and behavioral outliers:\n",
    "Keep the TemporalOutlierDetector and BehavioralOutlierDetector as they are, as these can still provide valuable insights at the product group level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e915b3f9-80a7-4f84-bec0-9dce13618c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalOutlierDetector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, time_column='timestamp', window_size='D', group_column='parent_asin'):\n",
    "        self.time_column = time_column\n",
    "        self.window_size = window_size\n",
    "        self.group_column = group_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['datetime'] = pd.to_datetime(X[self.time_column], unit='s', errors='coerce')\n",
    "        X['review_count'] = X.groupby([self.group_column, X['datetime'].dt.to_period(self.window_size)])['datetime'].transform('count')\n",
    "        X['temporal_outlier'] = (X['review_count'] > X.groupby(self.group_column)['review_count'].transform(lambda x: x.quantile(0.95))).astype(int)\n",
    "        return X[['temporal_outlier']].values\n",
    "\n",
    "\n",
    "class BehavioralOutlierDetector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, user_column='user_id', time_column='timestamp', rating_column='rating', window_size='D', review_threshold=3, rating_deviation_threshold=1.5, group_column='parent_asin'):\n",
    "        self.user_column = user_column\n",
    "        self.time_column = time_column\n",
    "        self.rating_column = rating_column\n",
    "        self.window_size = window_size\n",
    "        self.review_threshold = review_threshold\n",
    "        self.rating_deviation_threshold = rating_deviation_threshold\n",
    "        self.group_column = group_column\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['datetime'] = pd.to_datetime(X[self.time_column], errors='coerce')\n",
    "\n",
    "        # High-frequency user detection\n",
    "        user_review_counts = X.groupby([self.group_column, self.user_column, X['datetime'].dt.to_period(self.window_size)]).size().reset_index(name='review_count')\n",
    "        high_frequency_users = user_review_counts[user_review_counts['review_count'] > self.review_threshold][self.user_column].unique()\n",
    "\n",
    "        # Rating deviation detection\n",
    "        user_avg_ratings = X.groupby([self.group_column, self.user_column])[self.rating_column].mean().reset_index()\n",
    "        overall_avg_ratings = X.groupby(self.group_column)[self.rating_column].mean().reset_index()\n",
    "        deviating_users = user_avg_ratings.merge(overall_avg_ratings, on=self.group_column, suffixes=('_user', '_overall'))\n",
    "        deviating_users['rating_deviation'] = abs(deviating_users[f'{self.rating_column}_user'] - deviating_users[f'{self.rating_column}_overall'])\n",
    "        deviating_users = deviating_users[deviating_users['rating_deviation'] > self.rating_deviation_threshold][self.user_column].unique()\n",
    "\n",
    "        # Combine both outlier types into a single score\n",
    "        X['behavioral_outlier'] = ((X[self.user_column].isin(high_frequency_users) | \n",
    "                                    X[self.user_column].isin(deviating_users))).astype(int)\n",
    "\n",
    "        return X[['behavioral_outlier']].values\n",
    "\n",
    "class GroupwiseIsolationForest(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, contamination=0.1, random_state=42, max_samples=1000, n_estimators=100):\n",
    "        self.contamination = contamination\n",
    "        self.random_state = random_state\n",
    "        self.max_samples = max_samples\n",
    "        self.n_estimators = n_estimators\n",
    "        self.group_models = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        groups = X[X.columns[-1]]\n",
    "        features = X.iloc[:, :-1]\n",
    "        \n",
    "        for group in groups.unique():\n",
    "            group_mask = (groups == group)\n",
    "            group_features = features[group_mask]\n",
    "            \n",
    "            # If the group has more samples than max_samples, take a random sample\n",
    "            if len(group_features) > self.max_samples:\n",
    "                group_features = group_features.sample(n=self.max_samples, random_state=self.random_state)\n",
    "            \n",
    "            iso_forest = IsolationForest(contamination=self.contamination, \n",
    "                                         random_state=self.random_state, \n",
    "                                         max_samples=min(len(group_features), 256),\n",
    "                                         n_estimators=self.n_estimators, n_jobs=-1)\n",
    "            iso_forest.fit(group_features)\n",
    "            self.group_models[group] = iso_forest\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        groups = X[X.columns[-1]]\n",
    "        features = X.iloc[:, :-1]\n",
    "        outlier_scores = np.zeros(X.shape[0])\n",
    "        \n",
    "        for group in groups.unique():\n",
    "            group_mask = (groups == group)\n",
    "            group_features = features[group_mask]\n",
    "            \n",
    "            if group in self.group_models:\n",
    "                outlier_scores[group_mask] = self.group_models[group].decision_function(group_features)\n",
    "            else:\n",
    "                # If we encounter a new group during transform, we'll use the global mean\n",
    "                outlier_scores[group_mask] = np.mean(list(self.group_models.values())[0].decision_function(group_features))\n",
    "        \n",
    "        return outlier_scores.reshape(-1, 1)\n",
    "        \n",
    "class GroupwiseLOF(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_neighbors=20, contamination=0.1, min_group_size=10):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.contamination = contamination\n",
    "        self.min_group_size = min_group_size\n",
    "        self.group_models = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        groups = X[X.columns[-1]]\n",
    "        features = X.iloc[:, :-1]\n",
    "        \n",
    "        for group in groups.unique():\n",
    "            group_mask = (groups == group)\n",
    "            group_features = features[group_mask]\n",
    "            \n",
    "            if len(group_features) >= self.min_group_size:\n",
    "                n_neighbors = min(self.n_neighbors, len(group_features) - 1)\n",
    "                lof = LocalOutlierFactor(n_neighbors=n_neighbors, contamination=self.contamination, n_jobs=-1)\n",
    "                lof.fit(group_features)\n",
    "                self.group_models[group] = lof\n",
    "            else:\n",
    "                print(f\"Warning: Group {group} has fewer than {self.min_group_size} samples. Skipping LOF for this group.\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        groups = X[X.columns[-1]]\n",
    "        features = X.iloc[:, :-1]\n",
    "        outlier_scores = np.zeros(X.shape[0])\n",
    "        \n",
    "        for group in groups.unique():\n",
    "            group_mask = (groups == group)\n",
    "            group_features = features[group_mask]\n",
    "            \n",
    "            if group in self.group_models:\n",
    "                outlier_scores[group_mask] = -self.group_models[group].negative_outlier_factor_\n",
    "            else:\n",
    "                # For groups without a model (due to small size), assign a neutral score\n",
    "                outlier_scores[group_mask] = 0\n",
    "        \n",
    "        return outlier_scores.reshape(-1, 1)\n",
    "\n",
    "    def transform(self, X):\n",
    "        groups = X[X.columns[-1]]\n",
    "        features = X.iloc[:, :-1]\n",
    "        outlier_scores = np.zeros(X.shape[0])\n",
    "        \n",
    "        for group in groups.unique():\n",
    "            group_mask = (groups == group)\n",
    "            group_features = features[group_mask]\n",
    "            \n",
    "            if group in self.group_models:\n",
    "                outlier_scores[group_mask] = -self.group_models[group].negative_outlier_factor_\n",
    "            else:\n",
    "                # If we encounter a new group during transform, we'll use the global mean\n",
    "                outlier_scores[group_mask] = np.mean(-list(self.group_models.values())[0].negative_outlier_factor_)\n",
    "        \n",
    "        return outlier_scores.reshape(-1, 1)\n",
    "\n",
    "\n",
    "class TextOutlierTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, z_score_threshold=1.5):\n",
    "        self.z_score_threshold = z_score_threshold\n",
    "        self.vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        combined_text = X['combined_text_review'].values\n",
    "        self.vectorizer.fit(combined_text)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        combined_text = X['combined_text_review'].values\n",
    "        description = X['combined_text_product'].values\n",
    "        parent_asin = X['parent_asin'].values\n",
    "        \n",
    "        combined_text_tfidf = self.vectorizer.transform(combined_text)\n",
    "        description_tfidf = self.vectorizer.transform(description)\n",
    "        \n",
    "        outlier_scores = []\n",
    "        \n",
    "        for group_id in np.unique(parent_asin):\n",
    "            group_mask = (parent_asin == group_id)\n",
    "            group_texts = combined_text_tfidf[group_mask]\n",
    "            group_description = description_tfidf[group_mask][0]  # Assuming description is the same for all in group\n",
    "            \n",
    "            cosine_sim = cosine_similarity(group_texts, group_description)\n",
    "            \n",
    "            mean_sim = np.mean(cosine_sim)\n",
    "            std_sim = np.std(cosine_sim)\n",
    "            z_scores = (cosine_sim - mean_sim) / std_sim\n",
    "            \n",
    "            group_outlier_scores = (z_scores < -self.z_score_threshold).astype(float)\n",
    "            outlier_scores.extend(group_outlier_scores)\n",
    "        \n",
    "        return np.array(outlier_scores).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4abc1e7a-1fe2-48a7-a960-1eaf3a84bb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data preparation complete.\n",
      "Running outlier detection pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|                                                                                                | 0/5 [00:00<?, ?it/s]/tmp/ipykernel_23059/919406656.py:187: RuntimeWarning: invalid value encountered in divide\n",
      "  z_scores = (cosine_sim - mean_sim) / std_sim\n",
      "Processing: 100%|████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:13<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier detection complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data...\")\n",
    "df['helpful_vote'] = pd.to_numeric(df['helpful_vote'], errors='coerce')\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "df['verified_purchase'] = df['verified_purchase'].astype(int)\n",
    "# Ensure text columns are converted to strings\n",
    "text_columns = ['title_review', 'text', 'main_category', 'title_meta', 'description']\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "df['combined_text_review'] = df['title_review'] + ' ' + df['text']\n",
    "df['combined_text_product'] = df['main_category'] + ' ' + df['title_meta'] + ' ' + df['description']\n",
    "# Handle missing values\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_columns:\n",
    "    df[col] = df[col].fillna(df[col].mean())\n",
    "# For non-numeric columns, fill with a placeholder\n",
    "non_numeric_columns = df.select_dtypes(exclude=[np.number]).columns\n",
    "for col in non_numeric_columns:\n",
    "    df[col] = df[col].fillna(\"Unknown\")\n",
    "# Convert timestamp to datetime and handle invalid values\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', errors='coerce')\n",
    "print(\"Data preparation complete.\")\n",
    "\n",
    "feature_pipeline = ColumnTransformer([\n",
    "    ('num', StandardScaler(), ['rating', 'helpful_vote', 'verified_purchase', 'price', 'average_rating', 'rating_number']),\n",
    "    ('text', TextOutlierTransformer(z_score_threshold=1.5), ['combined_text_review', 'combined_text_product', 'parent_asin']),\n",
    "    ('temporal', TemporalOutlierDetector(group_column='parent_asin'), ['timestamp', 'parent_asin']),\n",
    "    ('behavioral', BehavioralOutlierDetector(group_column='parent_asin'), ['user_id', 'timestamp', 'rating', 'parent_asin']),\n",
    "])\n",
    "\n",
    "print(\"Running outlier detection pipeline...\")\n",
    "with tqdm(total=5, desc=\"Processing\") as pbar:\n",
    "    X_transformed = feature_pipeline.fit_transform(df)\n",
    "    pbar.update(1)\n",
    "\n",
    "    X_transformed = np.asarray(X_transformed)\n",
    "    if X_transformed.ndim == 1:\n",
    "        X_transformed = X_transformed.reshape(-1, 1)\n",
    "\n",
    "    iso_forest = IsolationForest(contamination=0.1, random_state=42, n_jobs=-1)\n",
    "    iso_forest_outliers = iso_forest.fit_predict(X_transformed)\n",
    "    pbar.update(1)\n",
    "\n",
    "    lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1, n_jobs=-1)\n",
    "    lof_outliers = lof.fit_predict(X_transformed)\n",
    "    pbar.update(1)\n",
    "\n",
    "    df['isolation_forest_outlier'] = (iso_forest_outliers == -1).astype(int)\n",
    "    df['lof_outlier'] = (lof_outliers == -1).astype(int)\n",
    "    df['text_outlier'] = (X_transformed[:, 0] > 0.5).astype(int)\n",
    "    df['temporal_outlier'] = (X_transformed[:, 1] > 0.5).astype(int)\n",
    "    df['high_frequency_outlier'] = (X_transformed[:, 2] > 0.5).astype(int)\n",
    "    df['rating_deviation_outlier'] = (X_transformed[:, 3] > 0.5).astype(int)\n",
    "    pbar.update(1)\n",
    "\n",
    "    df['outlier_score'] = (df['isolation_forest_outlier'] + \n",
    "                           df['lof_outlier'] + \n",
    "                           df['text_outlier'] + \n",
    "                           df['temporal_outlier'] + \n",
    "                           df['high_frequency_outlier'] + \n",
    "                           df['rating_deviation_outlier'])\n",
    "    df['is_outlier'] = (df['outlier_score'] >= 2).astype(int)\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"Outlier detection complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbcea72c-f62b-47f9-a590-7df82b64d5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Outlier Detection Results:\n",
      "temporal_outlier: 550 outliers (5.50%)\n",
      "behavioral_outlier: 550 outliers (5.50%)\n",
      "isolation_forest_outlier: 1000 outliers (10.00%)\n",
      "lof_outlier: 1000 outliers (10.00%)\n",
      "text_outlier: 6080 outliers (60.80%)\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "total_samples = len(df)\n",
    "print(f\"\\nOutlier Detection Results:\")\n",
    "for outlier_type in ['temporal_outlier', 'behavioral_outlier', 'isolation_forest_outlier', 'lof_outlier', 'text_outlier']:\n",
    "    count = df[outlier_type].sum()\n",
    "    print(f\"{outlier_type}: {count} outliers ({count/total_samples:.2%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2391d7d-dde7-4870-8eb7-9c0beb8ced11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_outlier\n",
       "0    84.35\n",
       "1    15.65\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_outlier'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a353316c-5199-43fe-95b1-d2a2835b53f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text_outlier\n",
       "1    0.608\n",
       "0    0.392\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_outlier'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "649464d5-625a-4561-b28d-907bd8935ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_review</th>\n",
       "      <th>text</th>\n",
       "      <th>main_category</th>\n",
       "      <th>title_meta</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spray</td>\n",
       "      <td>WOW what a great scent and it works very well.</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Soft &amp; Dri Soft Scent Aerosol Anti-Perspirant ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>...</td>\n",
       "      <td>Great product!</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Grip Hair Pins U Shaped Bobby Pins Hair Bun St...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Wooow thank you</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Argan Oil Hair Treatment Gift Set - 3 Value Pa...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Here's a tutorial for the product.</td>\n",
       "      <td>[[VIDEOID:b856b4ca5487125ecf1cfc26024ff47b]] R...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Vitamin C Serum For Face, Topical Facial Serum...</td>\n",
       "      <td>[\"Drop A Decade From Your Face from using our ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NYC lipsticks are pigment rich</td>\n",
       "      <td>Good color</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>NYC Expert Last Lip Color - 449 Creamy Mauve</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>So cute</td>\n",
       "      <td>If you are scrolling for a review to help you ...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>LEEYDESIGN Cat Ears Headband Party Headbands G...</td>\n",
       "      <td>['Product description', 'Item Features :', 'St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I can breath.</td>\n",
       "      <td>These are great! After wearing a mask all day,...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Mask Bracket, Protect Lipstick Lips - Internal...</td>\n",
       "      <td>['Unisex-adult', 'Protect Female makeup, do no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Great Product</td>\n",
       "      <td>These were perfect! Exactly as described, and ...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Pandahall 10pcs Golden Iron Clip-on Earring Co...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Outstanding quality and value👍</td>\n",
       "      <td>Love these products everything I have received...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Beard Brush &amp; Comb Set for Men – 100% Boar Bri...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wife is happy!</td>\n",
       "      <td>Purchased as a gift for my wife.  She is total...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Emjoi Micro-Pedi POWER Pro Callus Remover</td>\n",
       "      <td>[\"The Corded rechargeable Micro-Pedi Pro is id...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>so far so good</td>\n",
       "      <td>Tried this kind of roller for 2 weeks, got a c...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Jade Roller for Face Massager Natural Jade Sto...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Classic bonnet</td>\n",
       "      <td>Perfect for rainy weather</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Raines Rain Bonnet With Visor Adult, Colors Ma...</td>\n",
       "      <td>['100% Polyethylene One Size Fits Most']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great fragrance</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Bath and Body Works Snowflakes and Cashmere Bo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Love it!</td>\n",
       "      <td>I don't normally style my hair much which clip...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>2PCS Hair Clips Hairpin Headwear Styling Tools...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>love the feel of this and the size</td>\n",
       "      <td>this is good, I like the feel of this soap and...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Mitchell's Wool Fat Shave Refill Soap</td>\n",
       "      <td>[\"Mitchell's Wool Fat Soap was first produced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Best brush of my life</td>\n",
       "      <td>Truly the only brush that gets through my thic...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>CALA Wet N Silky Detangling Hair Brush (Black)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sonicare</td>\n",
       "      <td>We love our new Sonicare Essence e5500! This i...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Philips Sonicare HX5752/02 Essence Rechargeabl...</td>\n",
       "      <td>['Includes 2 contoured brush heads, charger ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Light</td>\n",
       "      <td>I use it to make UV keychains it perfect</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>UV LED Nail Dryer Curing Lamp for Gel Polish, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Beautiful colors!</td>\n",
       "      <td>This is a great variety pack of gel nail polis...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>gruciso 10Pcs Gel Nail Polish Set, Gel Polish ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lovely!</td>\n",
       "      <td>I bought this for a mah jongg buddy and notice...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Mah Jongg Tiles Guest Soap Set by Copa Judaica</td>\n",
       "      <td>['Set of 6 Mah Jong Soaps']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>We’ve got ears say cheers</td>\n",
       "      <td>Got these for my sons birthday party. They wer...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Picoway 20 Pack Mouse Ears Solid Black and Red...</td>\n",
       "      <td>['WHAT YOU GET:', 'We will s erve you 30-DAY M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>It’s hard to get it open, so I rub the catnip ...</td>\n",
       "      <td>It’s hard to get it open to put the catnip ins...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>DIYLOTA 2 PCS Cat Self Groomer with Catnip, Do...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Perfect for festivals</td>\n",
       "      <td>I absolutely love these!! Me and my two sister...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>4 Sets Mermaid Face Gems Rhinestone Tattoo Fes...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Price</td>\n",
       "      <td>Price expensive</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>THE MANE CHOICE- Easy On The Curls Detangling ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Nice!!</td>\n",
       "      <td>Beautiful colors.</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>SXC Cosmetics Nail Polish Set, 15ml/0.5oz Full...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Very good</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Mom to Mom Creme to Prevent Stretch Marks/Crem...</td>\n",
       "      <td>['The free gift is a Dcache Exclusive product ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Best price</td>\n",
       "      <td>Bought my niece a jar of Clinique moisturizer ...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Clinique iD Active Cartridge Concentrate #2 Fa...</td>\n",
       "      <td>['Clinique iD Active Cartridge Concentrate #2 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Great product! Highly recommend!</td>\n",
       "      <td>The colors are great and they are a nice size....</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>DSYLAI Travel Bottles Keychain Holder 4 Pieces...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Soft hold</td>\n",
       "      <td>So i luv this jar..a little goes a long way &amp; ...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Black Panther Strong Diamond Edges Braids Edge...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Love this brush.</td>\n",
       "      <td>It is so hard to find a curling iron with a sm...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Helen of Troy 1511 Brush Iron, White, 3/4 Inch...</td>\n",
       "      <td>['Helen of Troy 1511 Brush Iron, White, 3/4 In...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Love it</td>\n",
       "      <td>Love it</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>4 Pack -Jade Roller for Face and Neck Highest ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Great For Dry Skin</td>\n",
       "      <td>I am big on skincare, and I have been using re...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Great clippers!</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>New Crystal 24K Gold Collagen Eye Mask, Anti A...</td>\n",
       "      <td>['The excessive barking of your pet is a big p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Excellent  and fast shipping</td>\n",
       "      <td>Excellent  and fast shipping</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>OKAY | Black Jamaican Castor Oil Conditioner |...</td>\n",
       "      <td>['Stronger richer fuller hair growth needs to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Powder Foundation by Revlon, ColorStay Face Ma...</td>\n",
       "      <td>['A pressed powder unlike others, our ColorSta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Very nice</td>\n",
       "      <td>Love the choices, looks good on me.</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Beautywin Dreadlock Beads Colorful Cool Adjust...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>smaller than expected</td>\n",
       "      <td>Love this. holds all my pallets but was a tad ...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>byAlegory Acrylic Medium Eyeshadow Palette Mak...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>LOVE IT! Was skeptical at first</td>\n",
       "      <td>LOVE IT! Was skeptical at first, as it looked ...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>MelodySusie Large Acrylic Makeup Organizer - A...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Will continue buying! Amazing!</td>\n",
       "      <td>These are incredible! I struggle with putting ...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Brightup Magnetic Eyelashes with Eyeliner, 3D ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Red Heart #74</td>\n",
       "      <td>Rich Color perfect for Valentines day and Chri...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>1 Kleancolor Nail Polish Lacquer #74 Red Heart...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Amazing wig!</td>\n",
       "      <td>Beautiful wig! Texture is amazing, thickness i...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Vigorous Ombre Silver Wigs with Bangs Syntheti...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Soft glowy skin</td>\n",
       "      <td>I love this product it takes several steps out...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>DR.Frog Water-Fullcharge All in One (100ml)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>great product... I am a makeup artist and use ...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Face Secrets Small Ultra Wedge 80ct.</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Use more than once with proper cleaning, fits ...</td>\n",
       "      <td>Works great in a Listerine bottle, AND ONLY A ...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Listerine Pump for 1.5 or 1 Liter Bottles (1 P...</td>\n",
       "      <td>['Pump for 1 L and 1.5 L Bottles']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Stopped my itchy scalp</td>\n",
       "      <td>I've been using head and shoulders dry scalp a...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Every Man Jack Tea Tree Mens Thickening 2-in-1...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>BEST PRODUCT FOR STRETCHING LOBES EVER</td>\n",
       "      <td>Seriously the best thing I have ever used for ...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Gauge Gear Ear Stretching Balm | 10 ml Jar | P...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Works great</td>\n",
       "      <td>Vey easy to clean and price is great</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Head Shaver,Head Shavers for Bald Men,5D Float...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Me encanta</td>\n",
       "      <td>Me encanta este color</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>MIA SECRET 2OZ COVER BEIGE</td>\n",
       "      <td>['Mia Secret Acrylic Cover Powder in beige is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Super soft and squishy!</td>\n",
       "      <td>Came super fast and felt super soft and squish...</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>YABINA 5PCS Natural Compressed Essential BIG O...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Working great</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Spa Life Soothing Aloe And Collagen Lip Mask I...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         title_review  \\\n",
       "0                                               Spray   \n",
       "2                                                 ...   \n",
       "3                                          Five Stars   \n",
       "7                  Here's a tutorial for the product.   \n",
       "9                      NYC lipsticks are pigment rich   \n",
       "13                                            So cute   \n",
       "14                                      I can breath.   \n",
       "15                                      Great Product   \n",
       "16                     Outstanding quality and value👍   \n",
       "17                                     Wife is happy!   \n",
       "18                                     so far so good   \n",
       "19                                     Classic bonnet   \n",
       "20                                         Five Stars   \n",
       "21                                           Love it!   \n",
       "23                 love the feel of this and the size   \n",
       "28                              Best brush of my life   \n",
       "29                                           Sonicare   \n",
       "31                                              Light   \n",
       "33                                  Beautiful colors!   \n",
       "34                                            Lovely!   \n",
       "35                          We’ve got ears say cheers   \n",
       "36  It’s hard to get it open, so I rub the catnip ...   \n",
       "37                              Perfect for festivals   \n",
       "39                                              Price   \n",
       "40                                             Nice!!   \n",
       "41                                         Five Stars   \n",
       "42                                         Best price   \n",
       "43                   Great product! Highly recommend!   \n",
       "44                                          Soft hold   \n",
       "45                                   Love this brush.   \n",
       "46                                            Love it   \n",
       "47                                 Great For Dry Skin   \n",
       "48                                         Five Stars   \n",
       "49                       Excellent  and fast shipping   \n",
       "50                                         Five Stars   \n",
       "52                                          Very nice   \n",
       "53                              smaller than expected   \n",
       "54                    LOVE IT! Was skeptical at first   \n",
       "55                     Will continue buying! Amazing!   \n",
       "56                                      Red Heart #74   \n",
       "58                                       Amazing wig!   \n",
       "59                                    Soft glowy skin   \n",
       "60                                         Five Stars   \n",
       "61  Use more than once with proper cleaning, fits ...   \n",
       "62                             Stopped my itchy scalp   \n",
       "65             BEST PRODUCT FOR STRETCHING LOBES EVER   \n",
       "66                                        Works great   \n",
       "67                                         Me encanta   \n",
       "68                            Super soft and squishy!   \n",
       "69                                         Five Stars   \n",
       "\n",
       "                                                 text main_category  \\\n",
       "0      WOW what a great scent and it works very well.    All Beauty   \n",
       "2                                      Great product!    All Beauty   \n",
       "3                                     Wooow thank you    All Beauty   \n",
       "7   [[VIDEOID:b856b4ca5487125ecf1cfc26024ff47b]] R...    All Beauty   \n",
       "9                                          Good color    All Beauty   \n",
       "13  If you are scrolling for a review to help you ...    All Beauty   \n",
       "14  These are great! After wearing a mask all day,...    All Beauty   \n",
       "15  These were perfect! Exactly as described, and ...    All Beauty   \n",
       "16  Love these products everything I have received...    All Beauty   \n",
       "17  Purchased as a gift for my wife.  She is total...    All Beauty   \n",
       "18  Tried this kind of roller for 2 weeks, got a c...    All Beauty   \n",
       "19                          Perfect for rainy weather    All Beauty   \n",
       "20                                    Great fragrance    All Beauty   \n",
       "21  I don't normally style my hair much which clip...    All Beauty   \n",
       "23  this is good, I like the feel of this soap and...    All Beauty   \n",
       "28  Truly the only brush that gets through my thic...    All Beauty   \n",
       "29  We love our new Sonicare Essence e5500! This i...    All Beauty   \n",
       "31           I use it to make UV keychains it perfect    All Beauty   \n",
       "33  This is a great variety pack of gel nail polis...    All Beauty   \n",
       "34  I bought this for a mah jongg buddy and notice...    All Beauty   \n",
       "35  Got these for my sons birthday party. They wer...    All Beauty   \n",
       "36  It’s hard to get it open to put the catnip ins...    All Beauty   \n",
       "37  I absolutely love these!! Me and my two sister...    All Beauty   \n",
       "39                                    Price expensive    All Beauty   \n",
       "40                                  Beautiful colors.    All Beauty   \n",
       "41                                          Very good    All Beauty   \n",
       "42  Bought my niece a jar of Clinique moisturizer ...    All Beauty   \n",
       "43  The colors are great and they are a nice size....    All Beauty   \n",
       "44  So i luv this jar..a little goes a long way & ...    All Beauty   \n",
       "45  It is so hard to find a curling iron with a sm...    All Beauty   \n",
       "46                                            Love it    All Beauty   \n",
       "47  I am big on skincare, and I have been using re...    All Beauty   \n",
       "48                                    Great clippers!    All Beauty   \n",
       "49                       Excellent  and fast shipping    All Beauty   \n",
       "50                                          Excellent    All Beauty   \n",
       "52                Love the choices, looks good on me.    All Beauty   \n",
       "53  Love this. holds all my pallets but was a tad ...    All Beauty   \n",
       "54  LOVE IT! Was skeptical at first, as it looked ...    All Beauty   \n",
       "55  These are incredible! I struggle with putting ...    All Beauty   \n",
       "56  Rich Color perfect for Valentines day and Chri...    All Beauty   \n",
       "58  Beautiful wig! Texture is amazing, thickness i...    All Beauty   \n",
       "59  I love this product it takes several steps out...    All Beauty   \n",
       "60  great product... I am a makeup artist and use ...    All Beauty   \n",
       "61  Works great in a Listerine bottle, AND ONLY A ...    All Beauty   \n",
       "62  I've been using head and shoulders dry scalp a...    All Beauty   \n",
       "65  Seriously the best thing I have ever used for ...    All Beauty   \n",
       "66               Vey easy to clean and price is great    All Beauty   \n",
       "67                              Me encanta este color    All Beauty   \n",
       "68  Came super fast and felt super soft and squish...    All Beauty   \n",
       "69                                      Working great    All Beauty   \n",
       "\n",
       "                                           title_meta  \\\n",
       "0   Soft & Dri Soft Scent Aerosol Anti-Perspirant ...   \n",
       "2   Grip Hair Pins U Shaped Bobby Pins Hair Bun St...   \n",
       "3   Argan Oil Hair Treatment Gift Set - 3 Value Pa...   \n",
       "7   Vitamin C Serum For Face, Topical Facial Serum...   \n",
       "9        NYC Expert Last Lip Color - 449 Creamy Mauve   \n",
       "13  LEEYDESIGN Cat Ears Headband Party Headbands G...   \n",
       "14  Mask Bracket, Protect Lipstick Lips - Internal...   \n",
       "15  Pandahall 10pcs Golden Iron Clip-on Earring Co...   \n",
       "16  Beard Brush & Comb Set for Men – 100% Boar Bri...   \n",
       "17          Emjoi Micro-Pedi POWER Pro Callus Remover   \n",
       "18  Jade Roller for Face Massager Natural Jade Sto...   \n",
       "19  Raines Rain Bonnet With Visor Adult, Colors Ma...   \n",
       "20  Bath and Body Works Snowflakes and Cashmere Bo...   \n",
       "21  2PCS Hair Clips Hairpin Headwear Styling Tools...   \n",
       "23              Mitchell's Wool Fat Shave Refill Soap   \n",
       "28     CALA Wet N Silky Detangling Hair Brush (Black)   \n",
       "29  Philips Sonicare HX5752/02 Essence Rechargeabl...   \n",
       "31  UV LED Nail Dryer Curing Lamp for Gel Polish, ...   \n",
       "33  gruciso 10Pcs Gel Nail Polish Set, Gel Polish ...   \n",
       "34     Mah Jongg Tiles Guest Soap Set by Copa Judaica   \n",
       "35  Picoway 20 Pack Mouse Ears Solid Black and Red...   \n",
       "36  DIYLOTA 2 PCS Cat Self Groomer with Catnip, Do...   \n",
       "37  4 Sets Mermaid Face Gems Rhinestone Tattoo Fes...   \n",
       "39  THE MANE CHOICE- Easy On The Curls Detangling ...   \n",
       "40  SXC Cosmetics Nail Polish Set, 15ml/0.5oz Full...   \n",
       "41  Mom to Mom Creme to Prevent Stretch Marks/Crem...   \n",
       "42  Clinique iD Active Cartridge Concentrate #2 Fa...   \n",
       "43  DSYLAI Travel Bottles Keychain Holder 4 Pieces...   \n",
       "44  Black Panther Strong Diamond Edges Braids Edge...   \n",
       "45  Helen of Troy 1511 Brush Iron, White, 3/4 Inch...   \n",
       "46  4 Pack -Jade Roller for Face and Neck Highest ...   \n",
       "47                     &&&&&&&&&&&&&&&&&&&&&&&&&&&&&&   \n",
       "48  New Crystal 24K Gold Collagen Eye Mask, Anti A...   \n",
       "49  OKAY | Black Jamaican Castor Oil Conditioner |...   \n",
       "50  Powder Foundation by Revlon, ColorStay Face Ma...   \n",
       "52  Beautywin Dreadlock Beads Colorful Cool Adjust...   \n",
       "53  byAlegory Acrylic Medium Eyeshadow Palette Mak...   \n",
       "54  MelodySusie Large Acrylic Makeup Organizer - A...   \n",
       "55  Brightup Magnetic Eyelashes with Eyeliner, 3D ...   \n",
       "56  1 Kleancolor Nail Polish Lacquer #74 Red Heart...   \n",
       "58  Vigorous Ombre Silver Wigs with Bangs Syntheti...   \n",
       "59        DR.Frog Water-Fullcharge All in One (100ml)   \n",
       "60               Face Secrets Small Ultra Wedge 80ct.   \n",
       "61  Listerine Pump for 1.5 or 1 Liter Bottles (1 P...   \n",
       "62  Every Man Jack Tea Tree Mens Thickening 2-in-1...   \n",
       "65  Gauge Gear Ear Stretching Balm | 10 ml Jar | P...   \n",
       "66  Head Shaver,Head Shavers for Bald Men,5D Float...   \n",
       "67                         MIA SECRET 2OZ COVER BEIGE   \n",
       "68  YABINA 5PCS Natural Compressed Essential BIG O...   \n",
       "69  Spa Life Soothing Aloe And Collagen Lip Mask I...   \n",
       "\n",
       "                                          description  \n",
       "0                                                  []  \n",
       "2                                                  []  \n",
       "3                                                  []  \n",
       "7   [\"Drop A Decade From Your Face from using our ...  \n",
       "9                                                  []  \n",
       "13  ['Product description', 'Item Features :', 'St...  \n",
       "14  ['Unisex-adult', 'Protect Female makeup, do no...  \n",
       "15                                                 []  \n",
       "16                                                 []  \n",
       "17  [\"The Corded rechargeable Micro-Pedi Pro is id...  \n",
       "18                                                 []  \n",
       "19           ['100% Polyethylene One Size Fits Most']  \n",
       "20                                                 []  \n",
       "21                                                 []  \n",
       "23  [\"Mitchell's Wool Fat Soap was first produced ...  \n",
       "28                                                 []  \n",
       "29  ['Includes 2 contoured brush heads, charger ba...  \n",
       "31                                                 []  \n",
       "33                                                 []  \n",
       "34                        ['Set of 6 Mah Jong Soaps']  \n",
       "35  ['WHAT YOU GET:', 'We will s erve you 30-DAY M...  \n",
       "36                                                 []  \n",
       "37                                                 []  \n",
       "39                                                 []  \n",
       "40                                                 []  \n",
       "41  ['The free gift is a Dcache Exclusive product ...  \n",
       "42  ['Clinique iD Active Cartridge Concentrate #2 ...  \n",
       "43                                                 []  \n",
       "44                                                 []  \n",
       "45  ['Helen of Troy 1511 Brush Iron, White, 3/4 In...  \n",
       "46                                                 []  \n",
       "47                                                 []  \n",
       "48  ['The excessive barking of your pet is a big p...  \n",
       "49  ['Stronger richer fuller hair growth needs to ...  \n",
       "50  ['A pressed powder unlike others, our ColorSta...  \n",
       "52                                                 []  \n",
       "53                                                 []  \n",
       "54                                                 []  \n",
       "55                                                 []  \n",
       "56                                                 []  \n",
       "58                                                 []  \n",
       "59                                                 []  \n",
       "60                                                 []  \n",
       "61                 ['Pump for 1 L and 1.5 L Bottles']  \n",
       "62                                                 []  \n",
       "65                                                 []  \n",
       "66                                                 []  \n",
       "67  ['Mia Secret Acrylic Cover Powder in beige is ...  \n",
       "68                                                 []  \n",
       "69                                                 []  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[lambda x: (x['text_outlier']==1) & (x['description'].apply(lambda x: len(x) > 0))][['title_review','text', 'main_category', 'title_meta', 'description']][0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48205760-3f8c-4475-8f02-764cf8c15371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
